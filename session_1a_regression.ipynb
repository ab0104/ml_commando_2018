{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1a - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Python version: 3.6.3\n",
      "IPython version: 6.2.1\n",
      "numpy version: 1.13.3\n",
      "scikit-learn version: 0.19.1\n",
      "matplotlib version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import IPython\n",
    "import platform\n",
    "    \n",
    "print ('Python version:', platform.python_version())\n",
    "print ('IPython version:', IPython.__version__)\n",
    "print ('numpy version:', np.__version__)\n",
    "print ('scikit-learn version:', sklearn.__version__)\n",
    "print ('matplotlib version:', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_linear_regression(xs,ys, n_iter=1000):\n",
    "    N = len(xs)\n",
    "    m = 0.0\n",
    "    b = 0.0\n",
    "    learning_rate_alpha = 0.001\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        cost = 0\n",
    "        y_hats = []\n",
    "        for x in xs:\n",
    "            y_hats.append( b + m*x )\n",
    "        \n",
    "        for x,y,y_hat in zip(xs,ys,y_hats):\n",
    "            cost += (y_hat- y)**2\n",
    "        if i % 100 == 0:\n",
    "            print(\"cost at iteration {} = {}\".format(i,cost))\n",
    "\n",
    "        del_m = 0.0\n",
    "        del_b = 0.0    \n",
    "        for x,y,y_hat in zip(xs,ys,y_hats):  \n",
    "            del_m += (2/N)*( x * (y_hat - y) )\n",
    "            del_b += (2/N)*( y_hat - y )\n",
    "            \n",
    "        m = m - learning_rate_alpha * del_m\n",
    "        b = b - learning_rate_alpha * del_b\n",
    "    return y_hats, m, b, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2012]\n",
      " [-0.2269]\n",
      " [-0.6549]\n",
      " [-0.8689]\n",
      " [-0.0128]]\n",
      "[[ 0.2174]\n",
      " [-1.1082]\n",
      " [-0.578 ]\n",
      " [-0.8431]\n",
      " [ 0.4825]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "iris_sepal = X_iris[:,0:2]\n",
    "# iris_sepal = scaler.fit_transform(iris_sepal)\n",
    "# iris_petal = X_iris[:,2:4]\n",
    "\n",
    "setosa_sepal =iris_sepal[y_iris == 0]\n",
    "# setosa_petal =iris_petal[y_iris == 0]\n",
    "\n",
    "setosa_sepal_l = preprocessing.scale(setosa_sepal[:,0].reshape(-1,1))\n",
    "setosa_sepal_w = preprocessing.scale(setosa_sepal[:,1].reshape(-1,1))\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(setosa_sepal_l, setosa_sepal_w)\n",
    "\n",
    "pred = reg.predict(setosa_sepal_l)\n",
    "print(pred[0:5])\n",
    "print(setosa_sepal_w[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at iteration 0 = [ 50.]\n",
      "cost at iteration 100 = [ 40.7997]\n",
      "cost at iteration 200 = [ 34.635]\n",
      "cost at iteration 300 = [ 30.5044]\n",
      "cost at iteration 400 = [ 27.7366]\n",
      "cost at iteration 500 = [ 25.8821]\n",
      "cost at iteration 600 = [ 24.6395]\n",
      "cost at iteration 700 = [ 23.8068]\n",
      "cost at iteration 800 = [ 23.2489]\n",
      "cost at iteration 900 = [ 22.8751]\n",
      "m= [ 0.6459] b= [ -4.8907e-17]\n",
      "cost= [ 22.6267]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd1dfc23c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diy_predictions, m, b, cost = my_linear_regression(setosa_sepal_l, setosa_sepal_w)\n",
    "print(\"m=\",m,\"b=\",b)\n",
    "print(\"cost=\",cost)\n",
    "\n",
    "plt.scatter(setosa_sepal_l, setosa_sepal_w)\n",
    "plt.plot(setosa_sepal_l,y_hats, color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd1dfc23b38>]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd1dfc23ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = reg.predict(setosa_sepal_l)\n",
    "\n",
    "plt.scatter(setosa_sepal_l, setosa_sepal_w)\n",
    "# plot the regression line (should match our DIY routine)\n",
    "plt.plot(setosa_sepal_l, pred, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate linear regression\n",
    "\n",
    "To demonstrate multivariate regression in scikit-learn, we will apply it to a (very) simple and well-know problem: trying to predict the price of a house given some of its characteristics. As the dataset, we will use the 1978 Boston house price dataset (find the dataset description and attributes [here](http://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston dataset shape:(506, 13)\n",
      "Boston target shape:(506,)\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "features:\n",
      " [[  6.3200e-03   1.8000e+01   2.3100e+00   0.0000e+00   5.3800e-01\n",
      "    6.5750e+00   6.5200e+01   4.0900e+00   1.0000e+00   2.9600e+02\n",
      "    1.5300e+01   3.9690e+02   4.9800e+00]\n",
      " [  2.7310e-02   0.0000e+00   7.0700e+00   0.0000e+00   4.6900e-01\n",
      "    6.4210e+00   7.8900e+01   4.9671e+00   2.0000e+00   2.4200e+02\n",
      "    1.7800e+01   3.9690e+02   9.1400e+00]\n",
      " [  2.7290e-02   0.0000e+00   7.0700e+00   0.0000e+00   4.6900e-01\n",
      "    7.1850e+00   6.1100e+01   4.9671e+00   2.0000e+00   2.4200e+02\n",
      "    1.7800e+01   3.9283e+02   4.0300e+00]]\n",
      "prices:\n",
      " [ 24.   21.6  34.7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn import preprocessing\n",
    "boston = load_boston()\n",
    "print ('Boston dataset shape:{}'.format(boston.data.shape))\n",
    "print ('Boston target shape:{}'.format(boston.target.shape))\n",
    "print (boston.feature_names)\n",
    "\n",
    "\n",
    "X_train_boston_raw=boston.data\n",
    "y_train_boston_raw=boston.target\n",
    "\n",
    "numpy.set_printoptions(precision=4)\n",
    "print(\"features:\\n\", X_train_boston_raw[0:3,:])\n",
    "print(\"prices:\\n\", y_train_boston_raw[0:3])\n",
    "\n",
    "X_train_boston = preprocessing.scale(X_train_boston_raw) # shortcut to preprocessing.StandardScaler()\n",
    "y_train_boston = preprocessing.scale(y_train_boston_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using n-fold cross-validation\n",
    "\n",
    "Previously we've trained using a dataset split into train and test subsets.  Another way to split your data is to use cross validation.\n",
    "\n",
    "One of the main advantages of cross-validation is reducing the variance of the evaluation measures.  When you split the data manually, you will find that for each different split, your algorithm's performance will vary.  How do you know what is the right score?\n",
    "\n",
    "Evaluation within machine learning generally assumes that the distribution of classes on your training and testing sets are similar. If not, you may get results that are not a truthful measure of the classifier's performance. Cross-validation lets us mitigate this: we are averaging on k different models built on k different datasets, so we are reducing variance and probably producing more realistic performance scores for our models.\n",
    "\n",
    "Another benefit of cross-validation is that it allows us to make good use of the data we have available - each example acts as both a training datapoint and as a validation datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(_clf, X_train, y_train, n_folds):\n",
    "    _clf.fit(X_train, y_train)\n",
    "    print ('Score on training set: {:.2f}'.format(_clf.score(X_train, y_train)))\n",
    "    #create a k-fold cross validation iterator of k=5 folds\n",
    "    data =X_train.shape[0]\n",
    "    cv = sklearn.model_selection.KFold(n_splits= n_folds, shuffle=True, random_state=42)\n",
    "    scores = sklearn.model_selection.cross_val_score(_clf, X_train, y_train, cv=cv)\n",
    "    print ('Average score using {}-fold crossvalidation:{:.2f}'.format(n_folds,np.mean(scores)))\n",
    "    return _clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, we used accuracy, the proportion of correctly classified test-instances, to summarise our method’s performance.\n",
    "\n",
    "For regression, accuracy is a bad idea: we are predicting real values, so it's almost impossible to exactly predict the true value.\n",
    "\n",
    "Instead, the default score function in scikit-learn is the coefficient of determination (or $R^2$ score), which measures the proportion of outcome variation explained by the model. $R^2 \\in [0,1]$, and reaches 1 when the model perfectly predicts all the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.74\n",
      "Average score using 5-fold crossvalidation:0.71\n",
      "[-0.0898  0.0905 -0.0318  0.08   -0.1731  0.3157 -0.0126 -0.2974  0.1576\n",
      " -0.0956 -0.2109  0.0989 -0.3975]\n",
      "0.488099516178\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#Use a Stochastic Gradient Descent Regressor - this is a general purpose linear regressor good for large datasets\n",
    "clf_sgd = linear_model.SGDRegressor(loss='squared_loss', penalty=None, random_state=42, max_iter=10e5, tol=1e-4)\n",
    "train_and_evaluate(clf_sgd, X_train_boston, y_train_boston, 5)\n",
    "\n",
    "#print the hyperplane coefficients and their sum-of-squares\n",
    "\n",
    "print(clf_sgd.coef_)\n",
    "print(np.sum(np.square(clf_sgd.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.74\n",
      "Average score using 5-fold crossvalidation:0.71\n",
      "[-0.0897  0.0904 -0.0318  0.08   -0.173   0.3157 -0.0126 -0.2973  0.1575\n",
      " -0.0956 -0.2109  0.0989 -0.3974]\n",
      "0.487942944467 <-- coefficients should be a bit smaller\n"
     ]
    }
   ],
   "source": [
    "clf_sgd2 = linear_model.SGDRegressor(loss='squared_loss', penalty=\"l2\", random_state=42, max_iter=10e5, tol=1e-4)\n",
    "train_and_evaluate(clf_sgd2, X_train_boston, y_train_boston, 5)\n",
    "print(clf_sgd2.coef_)\n",
    "print(np.sum(np.square(clf_sgd2.coef_)), \"<-- coefficients should be a bit smaller\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, we used accuracy, the proportion of correctly classified test-instances, to summarise our method’s performance.\n",
    "\n",
    "For regression, accuracy is less useful: we are predicting continuous values, so it's virtually impossible to exactly predict the true value.\n",
    "\n",
    "Instead, the default score function in scikit-learn is the _coefficient of determination_ (or $R^2$ score), which measures the proportion of outcome variation explained by the model. $R^2 \\in [0,1]$, and reaches 1 when the model perfectly predicts all the target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra\n",
    "Use a _non-linear_ regressor such as sklearn's SVR, and cross validate it on the Boston data.  Is it better?  If so, why might this be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- We implemented linear regression using our own routine and using the sklearn libraries.\n",
    "- We tried out multivariate regression on the Boston house price dataset, using k-fold cross validation to test our estimators\n",
    "- We looked at the effect of regularisation on a SGD linear regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
